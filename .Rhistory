income <- c(34000, 123000, 21500)
income <- c(34000, 123000, 21500)
socioalNetwork_adjMatrix <- read.csv("C:/Users/kiran/OneDrive/Desktop/socioalNetwork_adjMatrix.csv", header=FALSE)
View(socioalNetwork_adjMatrix)
View(socioalNetwork_adjMatrix)
View(socioalNetwork_adjMatrix)
View(socioalNetwork_adjMatrix)
socioalNetwork=read.csv('socioalNetwork_adjMatrix.csv', header=T)
socioalnetwork=read.csv('socioalNetwork_adjMatrix.csv', header=T)
df=read.csv('socioalNetwork_adjMatrix.csv', header=T)
install.packages("igraph")
library(igraph)
df=read.csv('socioalNetwork_adjMatrix.csv', header=T)
install.packages("igraph")
library(igraph)
df=read.csv('socioalNetwork_adjMatrix.csv', header=T)
install.packages("igraph")
df=read.csv('socioalNetwork_adjMatrix.csv', header=T)
df=read.csv('socioalNetwork_adjMatrix.csv', header=T)
df=read.csv('socioalNetwork_adjMatrix.csv', header=T)
setwd("D:/Harsha's Project")
BJP <- read.csv("bjp_tweets.csv",header = TRUE)
install.packages("caret")
# Load necessary libraries
library(e1071)
library(caret)
library(dplyr)
library(tm)
#encodes the text in data frame using UTF
corpus = iconv(BJP$tweet, to='UTF-8', sub = "byte")
#text data stored in above object is stored & converted
corpus = Corpus(VectorSource(corpus))
#inspect
inspect(corpus[1:5])
#clean text
#change the text into lowercase
corpus = tm_map(corpus,tolower)
inspect(corpus[1:5])
#remove the punctuation
corpus = tm_map(corpus,removePunctuation)
inspect(corpus[1:5])
#remove the numerical digits
corpus = tm_map(corpus,removeNumbers)
inspect(corpus[1:5])
#remove the common stopwords
cleanset = tm_map(corpus, removeWords, stopwords('english'))
inspect(cleanset[1:5])
#to remove whitespaces
cleanset = tm_map(cleanset, stripWhitespace)
inspect(cleanset[1:5])
tdm = TermDocumentMatrix(cleanset)
tdm = as.matrix(tdm)
selected_terms <- c("bjp", "congress",  "rahul", "govt", "time", "like", "modi", "india", "indian", "amp", "attack", "one", "vote", "say", "pakistan",  "nation",  "elect", "peopl" )
# Subset the TDM based on selected rows
subset_tdm <- tdm[selected_terms, ]
View(subset_tdm)
transposed_df <- t(subset_tdm)
transposed_df$target <- BJP$target
transposed_df <- t(subset_tdm)
transposed_df1 <- as.data.frame(transposed_df)
transposed_df1$target <- BJP$target
install.packages("caret")
library(caret)
install.packages("caret")
install.packages("caret")
library(caret)
set.seed(123)
indices <- createDataPartition(transposed_df1$target, p = 0.7, list = FALSE)
train_data <- transposed_df1[indices, ]
test_data <- transposed_df1[-indices, ]
# Load the necessary libraries
library(e1071)
svm_model <- svm(target ~ ., data = train_data, kernel = "radial", cost = 1)
predictions <- predict(svm_model, newdata = test_data)
confusion_matrix <- table(predictions, test_data$target)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
setwd("D:/Harsha's Project")
BJP <- read.csv("bjp_tweets.csv",header = TRUE)
install.packages("caret")
# Load necessary libraries
library(e1071)
library(caret)
#library used for data manipulation
library(dplyr)
library(tm)
#encodes the text in data frame using UTF
corpus = iconv(BJP$tweet, to='UTF-8', sub = "byte")
#text data stored in above object is stored & converted
corpus = Corpus(VectorSource(corpus))
#inspect
inspect(corpus[1:5])
#clean text
#change the text into lowercase
corpus = tm_map(corpus,tolower)
inspect(corpus[1:5])
#remove the punctuation
corpus = tm_map(corpus,removePunctuation)
inspect(corpus[1:5])
#remove the numerical digits
corpus = tm_map(corpus,removeNumbers)
inspect(corpus[1:5])
#remove the common stopwords
cleanset = tm_map(corpus, removeWords, stopwords('english'))
inspect(cleanset[1:5])
#to remove whitespaces
cleanset = tm_map(cleanset, stripWhitespace)
inspect(cleanset[1:5])
dtm <- DocumentTermMatrix(cleanset)
dtm <- as.matrix(dtm)
dtm_df <- as.data.frame(as.matrix(dtm))
write.csv(dtm_df, file = "dtm_df.csv", row.names = FALSE)
View(dtm)
View(dtm)
dtm_df$target <- BJP$target
dtm_df$target <- BJP$target
selected_terms <- c("bjp", "congress",  "rahul", "govt", "time", "like", "modi", "india", "indian", "amp", "attack", "one", "vote", "say", "pakistan",  "nation",  "elect", "peopl" )
# Subset the data frame based on selected columns
subset_df <- dtm_df[, selected_terms]
subset_df <- dtm_df[, selected_terms]
selected_terms <- c("bjp", "congress",  "rahul", "govt", "time", "like", "modi", "india", "indian", "amp", "attack", "one", "vote", "say", "pakistan",  "nation",  "elect", "peopl", "target" )
subset_df <- dtm_df[, selected_terms]
# Assuming 'subset_df' is your data frame
subset_df$target <- factor(subset_df$target)
set.seed(123)
indices <- createDataPartition(transposed_df1$target, p = 0.7, list = FALSE)
indices <- createDataPartition(subset_df$target, p = 0.7, list = FALSE)
train_data <- transposed_df1[indices, ]
train_data <- subset_df[indices, ]
test_data <- subset_df[-indices, ]
svm_model <- svm(target ~ ., data = train_data, kernel = "radial", cost = 1)
predictions <- predict(svm_model, newdata = test_data)
confusion_matrix <- table(predictions, test_data$target)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
#####randomforest
install.packages("randomForest")
library(randomForest)
rf_model <- randomForest(target ~ ., data = train_data, ntree = 100)
# Make predictions on the test set
predictions_rf <- predict(rf_model, newdata = test_data)
# Evaluate the model
confusion_matrix_rf <- table(predictions_rf, test_data$target)
accuracy_rf <- sum(diag(confusion_matrix_rf)) / sum(confusion_matrix_rf)
cat("Accuracy (Random Forest):", accuracy_rf, "\n")
# Train a Naive Bayes model
nb_model <- naiveBayes(target ~ ., data = train_data)
# Make predictions on the test set
predictions_nb <- predict(nb_model, newdata = test_data)
# Evaluate the model
confusion_matrix_nb <- table(predictions_nb, test_data$target)
accuracy_nb <- sum(diag(confusion_matrix_nb)) / sum(confusion_matrix_nb)
cat("Accuracy (Naive Bayes):", accuracy_nb,Â "\n")
# Train a Naive Bayes model
nb_model <- naiveBayes(target ~ ., data = train_data)
# Make predictions on the test set
predictions_nb <- predict(nb_model, newdata = test_data)
# Evaluate the model
confusion_matrix_nb <- table(predictions_nb, test_data$target)
accuracy_nb <- sum(diag(confusion_matrix_nb)) / sum(confusion_matrix_nb)
cat("Accuracy (Naive Bayes):", accuracy_nb,"\n")
